import os
import sys
import pandas as pd
import numpy as np
import joblib
import ta
import logging
from tqdm import tqdm

# Ajouter le dossier racine du projet dans le path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../..")))

# Import de la configuration centrale des features
from src.utils.config_features import LSTM_FEATURES

# Configuration de logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def main():
    # Chemin absolu du fichier historique
    input_file = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../src/data/historique.csv"))
    logger.info(f"Chargement des donn√©es depuis {input_file}")
    try:
        df = pd.read_csv(input_file)
    except Exception as e:
        logger.error(f"Erreur lors du chargement du fichier {input_file} : {e}")
        return

    # V√©rifier que les colonnes essentielles existent (pour la r√©cup√©ration brute)
    required_columns = ["close", "high", "low", "volume"]
    missing_cols = [col for col in required_columns if col not in df.columns]
    if missing_cols:
        raise ValueError(f"üö® Colonnes manquantes dans '{input_file}' : {missing_cols}")

    # Ajout des indicateurs techniques
    df["SMA_20"] = df["close"].rolling(window=20).mean()
    df["SMA_50"] = df["close"].rolling(window=50).mean()
    df["EMA_20"] = df["close"].ewm(span=20, adjust=False).mean()
    df["RSI"] = ta.momentum.RSIIndicator(df["close"], window=14).rsi()
    macd = ta.trend.MACD(df["close"])
    df["MACD"] = macd.macd()
    df["MACD_signal"] = macd.macd_signal()
    bb = ta.volatility.BollingerBands(df["close"], window=20, window_dev=2)
    df["Bollinger_High"] = bb.bollinger_hband()
    df["Bollinger_Low"] = bb.bollinger_lband()
    df["ATR"] = ta.volatility.AverageTrueRange(df["high"], df["low"], df["close"], window=14).average_true_range()

    # Suppression des NaN g√©n√©r√©s par les indicateurs
    initial_len = len(df)
    df.dropna(inplace=True)
    logger.info(f"Suppression des NaN : {initial_len - len(df)} lignes retir√©es.")

    # V√©rifier qu'il y a au moins 14 lignes pour calculer l'ADX
    if len(df) < 14:
        logger.error("Pas assez de donn√©es pour calculer l'ADX (min requis: 14 lignes).")
        return

    df["ADX"] = ta.trend.ADXIndicator(df["high"], df["low"], df["close"], window=14).adx()

    # Utilisation de la configuration centrale pour d√©finir les features
    features_used = LSTM_FEATURES

    # Normalisation des donn√©es
    from sklearn.preprocessing import MinMaxScaler
    scaler = MinMaxScaler()
    scaled_data = scaler.fit_transform(df[features_used])
    # Sauvegarder le scaler dans src/models/
    scaler_path = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../src/models/scaler.pkl"))
    joblib.dump(scaler, scaler_path)
    logger.info(f"‚úÖ Scaler sauvegard√© sous '{scaler_path}' avec {len(df)} lignes utilis√©es.")

    # Pr√©paration des s√©quences pour le mod√®le LSTM
    SEQ_LEN = 60  # Nombre de bougies par s√©quence

    def create_sequences(data, seq_len):
        X, y = [], []
        for i in tqdm(range(len(data) - seq_len), desc="Cr√©ation des s√©quences", unit="seq"):
            X.append(data[i:i+seq_len])
            y.append(data[i+seq_len, 0])  # On pr√©dit la valeur de "close"
        return np.array(X), np.array(y)

    X, y = create_sequences(scaled_data, SEQ_LEN)

    if len(X) == 0 or len(y) == 0:
        raise ValueError("üö® Probl√®me lors de la cr√©ation des s√©quences, v√©rifiez la taille des donn√©es.")

    # S√©paration en train/validation (80/20)
    split = int(0.8 * len(X))
    X_train, y_train = X[:split], y[:split]
    X_val, y_val = X[split:], y[split:]
    logger.info(f"‚úÖ Donn√©es pr√©par√©es : X_train={X_train.shape}, X_val={X_val.shape}")

    # Sauvegarder les donn√©es pr√©trait√©es dans le dossier data
    base_data_path = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../src/data"))
    np.save(os.path.join(base_data_path, "X_train.npy"), X_train)
    np.save(os.path.join(base_data_path, "y_train.npy"), y_train)
    np.save(os.path.join(base_data_path, "X_val.npy"), X_val)
    np.save(os.path.join(base_data_path, "y_val.npy"), y_val)
    logger.info("‚úÖ Fichiers NumPy sauvegard√©s dans le dossier data.")

if __name__ == "__main__":
    main()
